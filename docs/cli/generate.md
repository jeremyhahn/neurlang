# nl generate

Generate complete Neurlang programs from natural language descriptions using slot-based code generation.

## Synopsis

```bash
nl generate <prompt> [options]
```

## Description

The `generate` command creates verified Neurlang programs by:

1. **Decomposing** the request into a SlotSpec (via rule-based templates or LLM)
2. **Filling** slots in parallel using a small local model
3. **Verifying** each slot and the integrated program
4. **Outputting** the complete .nl assembly file

This approach achieves 15-600x faster generation compared to LLM-based approaches.

## Arguments

| Argument | Description |
|----------|-------------|
| `<prompt>` | Natural language description of what to generate |

## Options

### Output Options

| Option | Description | Default |
|--------|-------------|---------|
| `-o, --output <file>` | Output file path | `output/<name>.nl` |
| `--show-spec` | Show the SlotSpec before filling | false |
| `--show-slots` | Show each filled slot | false |
| `--show-asm` | Show final assembly | false |

### Generation Mode

| Option | Description | Default |
|--------|-------------|---------|
| `--offline` | Use only rule-based decomposition (no LLM) | auto |
| `--llm` | Force LLM decomposition | auto |
| `--backend <name>` | LLM backend: claude, ollama, openai | auto |

### Performance Options

| Option | Description | Default |
|--------|-------------|---------|
| `--no-cache` | Disable slot cache | false |
| `--max-retries <n>` | Max retries per slot | 100 |
| `--parallel <n>` | Parallel slot filling threads | auto |
| `--benchmark` | Show timing breakdown | false |

### Model Options

| Option | Description | Default |
|--------|-------------|---------|
| `--model <path>` | Slot filler model path | `models/slot_filler.onnx` |
| `--engine <name>` | Inference engine: ort, tract, candle | auto |

### Test Options

| Option | Description | Default |
|--------|-------------|---------|
| `--dry-run` | Show SlotSpec without filling | false |
| `--skip-test` | Skip integration tests | false |
| `--test-timeout <ms>` | Test timeout in milliseconds | 5000 |

## Examples

### Basic Usage

```bash
# Generate SMTP server (auto-detects protocol spec)
nl generate "SMTP server"

# Generate with explicit output
nl generate "HTTP REST API" -o my_api.nl

# Show what would be generated
nl generate "Redis server" --dry-run
```

### Offline Mode

```bash
# Pure offline generation (no LLM, no network)
nl generate "SMTP server with TLS" --offline

# Force LLM for complex/novel requests
nl generate "custom binary protocol with heartbeat" --llm
```

### Debugging

```bash
# Show all intermediate steps
nl generate "FTP server" --show-spec --show-slots --show-asm

# Benchmark generation time
nl generate "HTTP server" --benchmark
```

### Output Control

```bash
# Save to specific file
nl generate "DNS server" -o dns_server.nl

# Run immediately after generation
nl generate "echo server" && nl run -i output/echo_server.nl
```

## Mode Selection

The command automatically selects between rule-based and LLM decomposition:

### Rule-Based (Offline, Fast)

Used when the request matches a known protocol spec:
- "SMTP server" -> `specs/protocols/smtp.yaml`
- "HTTP server" -> `specs/protocols/http.yaml`
- "Redis server" -> `specs/protocols/redis.yaml`

**Performance**: ~1-5ms decomposition

### LLM Decomposition

Used for novel or complex requests:
- "custom protocol with heartbeat mechanism"
- "game server with matchmaking"
- "chat server with rooms"

**Performance**: ~2-5s decomposition (then fast slot filling)

### Force Mode

```bash
# Always use rule-based (fails if no spec matches)
nl generate "SMTP server" --offline

# Always use LLM (even for known protocols)
nl generate "SMTP server" --llm
```

## Output Format

Generated files include:

```asm
; Generated by nl generate
; Prompt: SMTP server
; Template: tcp_server.skeleton
; Protocol: specs/protocols/smtp.yaml
; Generated: 2026-01-27T10:30:00Z

; @server: true
; @test: manual

.data:
    STATE_INIT = 0
    STATE_GREETED = 1
    ; ...

.text:
.entry:
    ; Server setup code
    ; ...

.helo_handler:
    ; SLOT_1: PatternMatch for HELO
    load.b r1, [r0]
    mov r2, 0x48
    ; ...

.send_helo_response:
    ; SLOT_2: ResponseBuilder for 250 Hello
    ; ...
```

## Performance

| Scenario | Time |
|----------|------|
| Offline with cache hits | ~20ms |
| Offline cold start | ~100ms |
| LLM decomposition + fill | ~3-5s |
| Integration test | ~10ms |

### Benchmark Output

```bash
$ nl generate "SMTP server" --benchmark

Slot-Based Generation Benchmark
===============================
Decomposition: 2.3ms (rule-based, specs/protocols/smtp.yaml)
Slot filling:
  - Cache lookups: 12 slots, 8 hits (66%)
  - Generation: 4 slots @ 48.2ms total
  - Verification: 12 slots @ 8.1ms total
Assembly: 1.2ms
Integration test: 12.4ms

Total: 72.2ms
Speedup vs LLM: ~40x
```

## Error Handling

### Slot Generation Failure

If a slot fails verification after max retries:

```
Error: Slot SLOT_3 (PatternMatch) failed after 100 attempts
Last error: Branch target 'no_match' not found
Context:
  Pattern: "RCPT TO:<{recipient:until:>}>"
  Input reg: r0

Suggestion: Check pattern syntax or provide more examples
```

### Integration Test Failure

If the integrated program fails tests:

```
Error: Integration test 'basic_session' failed
Step 3: Expected "250 OK\r\n", got "550 User not found\r\n"

Failing slot identified: SLOT_5 (ValidationHook)
Regenerating SLOT_5...

Retry successful after 2 attempts
```

### No Matching Spec

When offline mode can't find a protocol spec:

```
Error: No protocol spec matches "custom binary protocol"
Available specs:
  - smtp.yaml (SMTP server)
  - http.yaml (HTTP server)
  - redis.yaml (Redis protocol)
  - ftp.yaml (FTP server)
  - dns.yaml (DNS server)

Try: nl generate "custom binary protocol" --llm
```

## Configuration

### neurlang.toml

```toml
[generate]
# Default output directory
output_dir = "output"

# Default LLM backend
default_backend = "ollama"

# Cache settings
cache_enabled = true
cache_dir = ".slot_cache"

# Model paths
slot_model = "models/slot_filler.onnx"
```

### Environment Variables

| Variable | Description |
|----------|-------------|
| `NEURLANG_SLOT_MODEL` | Override slot filler model path |
| `NEURLANG_SLOT_CACHE` | Override cache directory |
| `NEURLANG_GEN_BACKEND` | Default LLM backend |

## See Also

- [Slot Architecture](../slot/README.md)
- [Protocol Specifications](../slot/protocol-specs.md)
- [Slot Types](../slot/slot-types.md)
- [nl prompt](./prompt.md) - Alternative LLM-based generation
- [nl run](./run.md) - Execute generated programs
